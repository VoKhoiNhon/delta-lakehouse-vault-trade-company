from pyspark.sql.types import StructType, StructField, ArrayType, StringType
schema = StructType([
    StructField('caption', StringType(), True),
    StructField('datasets', ArrayType(), True),
    StructField('first_seen', StringType(), True),
    StructField('id', StringType(), True),
    StructField('last_change', StringType(), True),
    StructField('last_seen', StringType(), True),
    StructField('authority', StringType(), True),
    StructField('authority_id', ArrayType(), True),
    StructField('country', StringType(), True),
    StructField('date', ArrayType(), True),
    StructField('description', ArrayType(), True),
    StructField('duration', ArrayType(), True),
    StructField('end_date', StringType(), True),
    StructField('entity', StringType(), True),
    StructField('listing_date', ArrayType(), True),
    StructField('modified_at', ArrayType(), True),
    StructField('program', ArrayType(), True),
    StructField('provisions', ArrayType(), True),
    StructField('publisher', ArrayType(), True),
    StructField('record_id', ArrayType(), True),
    StructField('reason', StringType(), True),
    StructField('source_url', StringType(), True),
    StructField('start_date', StringType(), True),
    StructField('status', ArrayType(), True),
    StructField('summary', ArrayType(), True),
    StructField('unsc_id', ArrayType(), True),
    StructField('schema', StringType(), True),
    StructField('load_date', StringType(), True)
])